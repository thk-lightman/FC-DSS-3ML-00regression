{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy as ps\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ps.demo_data(\"x1\",\"x2\",\"x3\",\"x4\",\"x5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.144044</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>-2.552990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>1.454274</td>\n",
       "      <td>1.494079</td>\n",
       "      <td>0.653619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978738</td>\n",
       "      <td>-0.151357</td>\n",
       "      <td>0.761038</td>\n",
       "      <td>-0.205158</td>\n",
       "      <td>0.864436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.240893</td>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.121675</td>\n",
       "      <td>0.313068</td>\n",
       "      <td>-0.742165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.867558</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0.443863</td>\n",
       "      <td>-0.854096</td>\n",
       "      <td>2.269755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5\n",
       "0  1.764052 -0.977278  0.144044  0.333674 -2.552990\n",
       "1  0.400157  0.950088  1.454274  1.494079  0.653619\n",
       "2  0.978738 -0.151357  0.761038 -0.205158  0.864436\n",
       "3  2.240893 -0.103219  0.121675  0.313068 -0.742165\n",
       "4  1.867558  0.410599  0.443863 -0.854096  2.269755"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dmatrix in module patsy.highlevel:\n",
      "\n",
      "dmatrix(formula_like, data={}, eval_env=0, NA_action='drop', return_type='matrix')\n",
      "    Construct a single design matrix given a formula_like and data.\n",
      "    \n",
      "    :arg formula_like: An object that can be used to construct a design\n",
      "      matrix. See below.\n",
      "    :arg data: A dict-like object that can be used to look up variables\n",
      "      referenced in `formula_like`.\n",
      "    :arg eval_env: Either a :class:`EvalEnvironment` which will be used to\n",
      "      look up any variables referenced in `formula_like` that cannot be\n",
      "      found in `data`, or else a depth represented as an\n",
      "      integer which will be passed to :meth:`EvalEnvironment.capture`.\n",
      "      ``eval_env=0`` means to use the context of the function calling\n",
      "      :func:`dmatrix` for lookups. If calling this function from a library,\n",
      "      you probably want ``eval_env=1``, which means that variables should be\n",
      "      resolved in *your* caller's namespace.\n",
      "    :arg NA_action: What to do with rows that contain missing values. You can\n",
      "      ``\"drop\"`` them, ``\"raise\"`` an error, or for customization, pass an\n",
      "      :class:`NAAction` object. See :class:`NAAction` for details on what\n",
      "      values count as 'missing' (and how to alter this).\n",
      "    :arg return_type: Either ``\"matrix\"`` or ``\"dataframe\"``. See below.\n",
      "    \n",
      "    The `formula_like` can take a variety of forms. You can use any of the\n",
      "    following:\n",
      "    \n",
      "    * (The most common option) A formula string like ``\"x1 + x2\"`` (for\n",
      "      :func:`dmatrix`) or ``\"y ~ x1 + x2\"`` (for :func:`dmatrices`). For\n",
      "      details see :ref:`formulas`.\n",
      "    * A :class:`ModelDesc`, which is a Python object representation of a\n",
      "      formula. See :ref:`formulas` and :ref:`expert-model-specification` for\n",
      "      details.\n",
      "    * A :class:`DesignInfo`.\n",
      "    * An object that has a method called :meth:`__patsy_get_model_desc__`.\n",
      "      For details see :ref:`expert-model-specification`.\n",
      "    * A numpy array_like (for :func:`dmatrix`) or a tuple\n",
      "      (array_like, array_like) (for :func:`dmatrices`). These will have\n",
      "      metadata added, representation normalized, and then be returned\n",
      "      directly. In this case `data` and `eval_env` are\n",
      "      ignored. There is special handling for two cases:\n",
      "    \n",
      "      * :class:`DesignMatrix` objects will have their :class:`DesignInfo`\n",
      "        preserved. This allows you to set up custom column names and term\n",
      "        information even if you aren't using the rest of the patsy\n",
      "        machinery.\n",
      "      * :class:`pandas.DataFrame` or :class:`pandas.Series` objects will have\n",
      "        their (row) indexes checked. If two are passed in, their indexes must\n",
      "        be aligned. If ``return_type=\"dataframe\"``, then their indexes will be\n",
      "        preserved on the output.\n",
      "    \n",
      "    Regardless of the input, the return type is always either:\n",
      "    \n",
      "    * A :class:`DesignMatrix`, if ``return_type=\"matrix\"`` (the default)\n",
      "    * A :class:`pandas.DataFrame`, if ``return_type=\"dataframe\"``.\n",
      "    \n",
      "    The actual contents of the design matrix is identical in both cases, and\n",
      "    in both cases a :class:`DesignInfo` object will be available in a\n",
      "    ``.design_info`` attribute on the return value. However, for\n",
      "    ``return_type=\"dataframe\"``, any pandas indexes on the input (either in\n",
      "    `data` or directly passed through `formula_like`) will be preserved, which\n",
      "    may be useful for e.g. time-series models.\n",
      "    \n",
      "    .. versionadded:: 0.2.0\n",
      "       The ``NA_action`` argument.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ps.dmatrix)\n",
    "eval_env=0\n",
    "NA_action='drop'\n",
    "return_type='matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignInfo(['sex[female]', 'sex[male]', 'survived', 'pclass', 'age'],\n",
       "           factor_infos={EvalFactor('survived'): FactorInfo(factor=EvalFactor('survived'),\n",
       "                                    type='numerical',\n",
       "                                    state=<factor state>,\n",
       "                                    num_columns=1),\n",
       "                         EvalFactor('pclass'): FactorInfo(factor=EvalFactor('pclass'),\n",
       "                                    type='numerical',\n",
       "                                    state=<factor state>,\n",
       "                                    num_columns=1),\n",
       "                         EvalFactor('sex'): FactorInfo(factor=EvalFactor('sex'),\n",
       "                                    type='categorical',\n",
       "                                    state=<factor state>,\n",
       "                                    categories=('female', 'male')),\n",
       "                         EvalFactor('age'): FactorInfo(factor=EvalFactor('age'),\n",
       "                                    type='numerical',\n",
       "                                    state=<factor state>,\n",
       "                                    num_columns=1)},\n",
       "           term_codings=OrderedDict([(Term([EvalFactor('sex')]),\n",
       "                                      [SubtermInfo(factors=(EvalFactor('sex'),),\n",
       "                                                   contrast_matrices={EvalFactor('sex'): ContrastMatrix(array([[1., 0.],\n",
       "                                                                                            [0., 1.]]),\n",
       "                                                                                     ['[female]',\n",
       "                                                                                      '[male]'])},\n",
       "                                                   num_columns=2)]),\n",
       "                                     (Term([EvalFactor('survived')]),\n",
       "                                      [SubtermInfo(factors=(EvalFactor('survived'),),\n",
       "                                                   contrast_matrices={},\n",
       "                                                   num_columns=1)]),\n",
       "                                     (Term([EvalFactor('pclass')]),\n",
       "                                      [SubtermInfo(factors=(EvalFactor('pclass'),),\n",
       "                                                   contrast_matrices={},\n",
       "                                                   num_columns=1)]),\n",
       "                                     (Term([EvalFactor('age')]),\n",
       "                                      [SubtermInfo(factors=(EvalFactor('age'),),\n",
       "                                                   contrast_matrices={},\n",
       "                                                   num_columns=1)])]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.dmatrix(\"survived + pclass + sex + age + 0\", data = titanic, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignInfo(['center(x1)'],\n",
       "           factor_infos={EvalFactor('center(x1)'): FactorInfo(factor=EvalFactor('center(x1)'),\n",
       "                                    type='numerical',\n",
       "                                    state=<factor state>,\n",
       "                                    num_columns=1)},\n",
       "           term_codings=OrderedDict([(Term([EvalFactor('center(x1)')]),\n",
       "                                      [SubtermInfo(factors=(EvalFactor('center(x1)'),),\n",
       "                                                   contrast_matrices={},\n",
       "                                                   num_columns=1)])]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.dmatrix(\"center(x1) + 0\", df).design_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(7).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaler = StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StandardScaler in module sklearn.preprocessing._data object:\n",
      "\n",
      "class StandardScaler(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  StandardScaler(*, copy=True, with_mean=True, with_std=True)\n",
      " |  \n",
      " |  Standardize features by removing the mean and scaling to unit variance\n",
      " |  \n",
      " |  The standard score of a sample `x` is calculated as:\n",
      " |  \n",
      " |      z = (x - u) / s\n",
      " |  \n",
      " |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      " |  and `s` is the standard deviation of the training samples or one if\n",
      " |  `with_std=False`.\n",
      " |  \n",
      " |  Centering and scaling happen independently on each feature by computing\n",
      " |  the relevant statistics on the samples in the training set. Mean and\n",
      " |  standard deviation are then stored to be used on later data using\n",
      " |  :meth:`transform`.\n",
      " |  \n",
      " |  Standardization of a dataset is a common requirement for many\n",
      " |  machine learning estimators: they might behave badly if the\n",
      " |  individual features do not more or less look like standard normally\n",
      " |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      " |  \n",
      " |  For instance many elements used in the objective function of\n",
      " |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      " |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      " |  all features are centered around 0 and have variance in the same\n",
      " |  order. If a feature has a variance that is orders of magnitude larger\n",
      " |  that others, it might dominate the objective function and make the\n",
      " |  estimator unable to learn from other features correctly as expected.\n",
      " |  \n",
      " |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      " |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  copy : boolean, optional, default True\n",
      " |      If False, try to avoid a copy and do inplace scaling instead.\n",
      " |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      " |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      " |      returned.\n",
      " |  \n",
      " |  with_mean : boolean, True by default\n",
      " |      If True, center the data before scaling.\n",
      " |      This does not work (and will raise an exception) when attempted on\n",
      " |      sparse matrices, because centering them entails building a dense\n",
      " |      matrix which in common use cases is likely to be too large to fit in\n",
      " |      memory.\n",
      " |  \n",
      " |  with_std : boolean, True by default\n",
      " |      If True, scale the data to unit variance (or equivalently,\n",
      " |      unit standard deviation).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scale_ : ndarray or None, shape (n_features,)\n",
      " |      Per feature relative scaling of the data. This is calculated using\n",
      " |      `np.sqrt(var_)`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_*\n",
      " |  \n",
      " |  mean_ : ndarray or None, shape (n_features,)\n",
      " |      The mean value for each feature in the training set.\n",
      " |      Equal to ``None`` when ``with_mean=False``.\n",
      " |  \n",
      " |  var_ : ndarray or None, shape (n_features,)\n",
      " |      The variance for each feature in the training set. Used to compute\n",
      " |      `scale_`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |  n_samples_seen_ : int or array, shape (n_features,)\n",
      " |      The number of samples processed by the estimator for each feature.\n",
      " |      If there are not missing samples, the ``n_samples_seen`` will be an\n",
      " |      integer, otherwise it will be an array.\n",
      " |      Will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      " |  >>> scaler = StandardScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  StandardScaler()\n",
      " |  >>> print(scaler.mean_)\n",
      " |  [0.5 0.5]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[-1. -1.]\n",
      " |   [-1. -1.]\n",
      " |   [ 1.  1.]\n",
      " |   [ 1.  1.]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[3. 3.]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  :class:`sklearn.decomposition.PCA`\n",
      " |      Further removes the linear correlation across features with 'whiten=True'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  We use a biased estimator for the standard deviation, equivalent to\n",
      " |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      " |  affect model performance.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StandardScaler\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, copy=True, with_mean=True, with_std=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the mean and std to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y\n",
      " |          Ignored\n",
      " |  \n",
      " |  inverse_transform(self, X, copy=None)\n",
      " |      Scale back the data to the original representation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : array-like, shape [n_samples, n_features]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of mean and std on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      " |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      " |      for computing the sample variance: Analysis and recommendations.\"\n",
      " |      The American Statistician 37.3 (1983): 242-247:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Transformer instance.\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Perform standardization by centering and scaling\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,), default=None\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function vstack in module numpy:\n",
      "\n",
      "vstack(tup)\n",
      "    Stack arrays in sequence vertically (row wise).\n",
      "    \n",
      "    This is equivalent to concatenation along the first axis after 1-D arrays\n",
      "    of shape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n",
      "    `vsplit`.\n",
      "    \n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        The arrays must have the same shape along all but the first axis.\n",
      "        1-D arrays must have the same length.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays, will be at least 2-D.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    block : Assemble an nd-array from nested lists of blocks.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    column_stack : Stack 1-D arrays as columns into a 2-D array.\n",
      "    vsplit : Split an array into multiple sub-arrays vertically (row-wise).\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([2, 3, 4])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1, 2, 3],\n",
      "           [2, 3, 4]])\n",
      "    \n",
      "    >>> a = np.array([[1], [2], [3]])\n",
      "    >>> b = np.array([[2], [3], [4]])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1],\n",
      "           [2],\n",
      "           [3],\n",
      "           [2],\n",
      "           [3],\n",
      "           [4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.vstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0],\n",
       "       [   1],\n",
       "       [   2],\n",
       "       [   3],\n",
       "       [   4],\n",
       "       [   5],\n",
       "       [   6],\n",
       "       [1000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = np.vstack([X, [[1000]]])\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.00000000e+00],\n",
       "       [-7.14285714e-01],\n",
       "       [-4.28571429e-01],\n",
       "       [-1.42857143e-01],\n",
       "       [ 1.42857143e-01],\n",
       "       [ 4.28571429e-01],\n",
       "       [ 7.14285714e-01],\n",
       "       [ 2.84714286e+02]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit_transform(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PolynomialFeatures in module sklearn.preprocessing._data:\n",
      "\n",
      "class PolynomialFeatures(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  PolynomialFeatures(degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
      " |  \n",
      " |  Generate polynomial and interaction features.\n",
      " |  \n",
      " |  Generate a new feature matrix consisting of all polynomial combinations\n",
      " |  of the features with degree less than or equal to the specified degree.\n",
      " |  For example, if an input sample is two dimensional and of the form\n",
      " |  [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  degree : integer\n",
      " |      The degree of the polynomial features. Default = 2.\n",
      " |  \n",
      " |  interaction_only : boolean, default = False\n",
      " |      If true, only interaction features are produced: features that are\n",
      " |      products of at most ``degree`` *distinct* input features (so not\n",
      " |      ``x[1] ** 2``, ``x[0] * x[2] ** 3``, etc.).\n",
      " |  \n",
      " |  include_bias : boolean\n",
      " |      If True (default), then include a bias column, the feature in which\n",
      " |      all polynomial powers are zero (i.e. a column of ones - acts as an\n",
      " |      intercept term in a linear model).\n",
      " |  \n",
      " |  order : str in {'C', 'F'}, default 'C'\n",
      " |      Order of output array in the dense case. 'F' order is faster to\n",
      " |      compute, but may slow down subsequent estimators.\n",
      " |  \n",
      " |      .. versionadded:: 0.21\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.preprocessing import PolynomialFeatures\n",
      " |  >>> X = np.arange(6).reshape(3, 2)\n",
      " |  >>> X\n",
      " |  array([[0, 1],\n",
      " |         [2, 3],\n",
      " |         [4, 5]])\n",
      " |  >>> poly = PolynomialFeatures(2)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
      " |         [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
      " |         [ 1.,  4.,  5., 16., 20., 25.]])\n",
      " |  >>> poly = PolynomialFeatures(interaction_only=True)\n",
      " |  >>> poly.fit_transform(X)\n",
      " |  array([[ 1.,  0.,  1.,  0.],\n",
      " |         [ 1.,  2.,  3.,  6.],\n",
      " |         [ 1.,  4.,  5., 20.]])\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  powers_ : array, shape (n_output_features, n_input_features)\n",
      " |      powers_[i, j] is the exponent of the jth input in the ith output.\n",
      " |  \n",
      " |  n_input_features_ : int\n",
      " |      The total number of input features.\n",
      " |  \n",
      " |  n_output_features_ : int\n",
      " |      The total number of polynomial output features. The number of output\n",
      " |      features is computed by iterating over all suitably sized combinations\n",
      " |      of input features.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Be aware that the number of features in the output array scales\n",
      " |  polynomially in the number of features of the input array, and\n",
      " |  exponentially in the degree. High degrees can cause overfitting.\n",
      " |  \n",
      " |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      " |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PolynomialFeatures\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute number of output features.\n",
      " |      \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          The data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : instance\n",
      " |  \n",
      " |  get_feature_names(self, input_features=None)\n",
      " |      Return feature names for output features\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : list of string, length n_features, optional\n",
      " |          String names for input features if available. By default,\n",
      " |          \"x0\", \"x1\", ... \"xn_features\" is used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      output_feature_names : list of string, length n_output_features\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform data to polynomial features\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or CSR/CSC sparse matrix, shape [n_samples, n_features]\n",
      " |          The data to transform, row by row.\n",
      " |      \n",
      " |          Prefer CSR over CSC for sparse input (for speed), but CSC is\n",
      " |          required if the degree is 4 or higher. If the degree is less than\n",
      " |          4 and the input format is CSC, it will be converted to CSR, have\n",
      " |          its polynomial features generated, then converted back to CSC.\n",
      " |      \n",
      " |          If the degree is 2 or 3, the method described in \"Leveraging\n",
      " |          Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices\n",
      " |          Using K-Simplex Numbers\" by Andrew Nystrom and John Hughes is\n",
      " |          used, which is much faster than the method used on CSC input. For\n",
      " |          this reason, a CSC input will be converted to CSR, and the output\n",
      " |          will be converted back to CSC prior to being returned, hence the\n",
      " |          preference of CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      XP : np.ndarray or CSR/CSC sparse matrix, shape [n_samples, NP]\n",
      " |          The matrix of features, where NP is the number of polynomial\n",
      " |          features generated from the combination of inputs.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  powers_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,), default=None\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PolynomialFeatures)\n",
    "\n",
    "degree : integer\n",
    "  The degree of the polynomial features. Default = 2.\n",
    "\n",
    "interaction_only : boolean, default = False\n",
    "  If true, only interaction features are produced: features that are\n",
    "  products of at most ``degree`` *distinct* input features (so not\n",
    "  ``x[1] ** 2``, ``x[0] * x[2] ** 3``, etc.).\n",
    "\n",
    "include_bias : boolean\n",
    "  If True (default), then include a bias column, the feature in which\n",
    "  all polynomial powers are zero (i.e. a column of ones - acts as an\n",
    "  intercept term in a linear model).\n",
    "\n",
    "order : str in {'C', 'F'}, default 'C'\n",
    "  Order of output array in the dense case. 'F' order is faster to\n",
    "  compute, but may slow down subsequent estimators.\n",
    "\n",
    "  .. versionadded:: 0.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0],\n",
       "       [ 90],\n",
       "       [180],\n",
       "       [270],\n",
       "       [360],\n",
       "       [450],\n",
       "       [540],\n",
       "       [630],\n",
       "       [720]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = 90 * np.arange(9).reshape(-1, 1) \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 44033 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54364 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54788 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 49340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 54632 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 44033 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 46020 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54364 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54788 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 49340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 54632 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 49688 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def degree2sincos(X):\n",
    "    x0 = np.sin(X * np.pi / 180)\n",
    "    x1 = np.cos(X * np.pi / 180)\n",
    "    X_new = np.hstack([x0, x1])\n",
    "    return X_new\n",
    "\n",
    "X2 = FunctionTransformer(degree2sincos).fit_transform(X)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(X, marker=\"o\")\n",
    "plt.yticks(X.flatten())\n",
    "plt.title(\" \")\n",
    "plt.subplot(212)\n",
    "plt.plot(X2, marker=\"o\")\n",
    "plt.title(\" \")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x\n",
       "0    Male\n",
       "1  Female"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([\"Male\", \"Female\"], columns=[\"x\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (2, 2)\n",
       "  Intercept  C(x, Treatment('Male'))[T.Female]\n",
       "          1                                  0\n",
       "          1                                  1\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    \"C(x, Treatment('Male'))\" (column 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = ps.dmatrix(\"C(x, Treatment('Male'))\", data = df1)\n",
    "# dm = ps.dmatrix(\"x + 0\", data = df1)\n",
    "dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
